{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "I4W9YP4Afg6o"
   },
   "source": [
    "## Coding Exercise #0509"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "9Zgvhojgfg6q"
   },
   "outputs": [],
   "source": [
    "import nltk\n",
    "from numpy.random import randint, seed\n",
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oM_26Y4Mfg6r"
   },
   "source": [
    "### 1. n-Gram based autofill:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "O84NX5nafg6r"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_text_from_url' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Text data for training.\u001b[39;00m\n\u001b[0;32m      2\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://es.wikipedia.org/wiki/Aprendizaje_autom\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mC3\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124mA1tico\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m my_text \u001b[38;5;241m=\u001b[39m get_text_from_url(url)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'get_text_from_url' is not defined"
     ]
    }
   ],
   "source": [
    "# Text data for training.\n",
    "my_text = \"\"\"Machine learning is the scientific study of algorithms and statistical models that computer systems use to effectively perform a specific task without using explicit instructions, relying on patterns and inference instead. It is seen as a subset of artificial intelligence. Machine learning algorithms build a mathematical model of sample data, known as \"training data\", in order to make predictions or decisions without being explicitly programmed to perform the task.[1][2]:2 Machine learning algorithms are used in the applications of email filtering, detection of network intruders, and computer vision, where it is infeasible to develop an algorithm of specific instructions for performing the task. Machine learning is closely related to computational statistics, which focuses on making predictions using computers. The study of mathematical optimization delivers methods, theory and application domains to the field of machine learning. Data mining is a field of study within machine learning, and focuses on exploratory data analysis through unsupervised learning In its application across business problems, machine learning is also referred to as predictive analytics.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "yQtXUgeafg6s"
   },
   "outputs": [],
   "source": [
    "my_text = [my_text.lower()]                       # Convert to lowercase and make a list. => Required by the CountVectorizer()."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dDjqvXT9fg6s"
   },
   "source": [
    "#### 1.1. n-Gram trial run:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zaqiuUHWfg6t"
   },
   "outputs": [],
   "source": [
    "n = 3                                                            # Can be changed to a number equal or larger than 2.\n",
    "n_min = n\n",
    "n_max = n\n",
    "n_gram_type = 'word'                                             # n-Gram with words.\n",
    "vectorizer = CountVectorizer(ngram_range=(n_min,n_max), analyzer = n_gram_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cpSy7o6xfg6t"
   },
   "outputs": [],
   "source": [
    "n_grams = vectorizer.fit(my_text).get_feature_names_out()            # Get the n-Grams as a list.\n",
    "n_gram_cts = vectorizer.transform(my_text).toarray()             #  The output is an array of array.\n",
    "n_gram_cts = list(n_gram_cts[0])                                 # Convert into a simple list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "vYNkK6Qqfg6u",
    "outputId": "5c729149-23aa-49b7-8e8e-d75498f2eb8a"
   },
   "outputs": [],
   "source": [
    "list(zip(n_grams,n_gram_cts))                                    # Make a list of tuples and show."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J7ijveMqfg6v"
   },
   "source": [
    "#### 1.2. Train by making a dictionary based on n-Grams:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VHZzL02dfg6v"
   },
   "outputs": [],
   "source": [
    "n = 3                                                           # Can be changed to a number equal or larger than 2.\n",
    "n_min = n\n",
    "n_max = n\n",
    "n_gram_type = 'word'\n",
    "vectorizer = CountVectorizer(ngram_range=(n_min,n_max), analyzer = n_gram_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.download('punkt_tab')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "50cV0anrfg6w"
   },
   "outputs": [],
   "source": [
    "n_grams = vectorizer.fit(my_text).get_feature_names_out()           # A list of n-Grams.\n",
    "my_dict = {}\n",
    "for a_gram in n_grams:\n",
    "    words = nltk.word_tokenize(a_gram)\n",
    "    a_nm1_gram = ' '.join(words[0:n-1])                         # (n-1)-Gram.\n",
    "    next_word = words[-1]                                       # Word after the a_nm1_gram.\n",
    "    if a_nm1_gram not in my_dict.keys():\n",
    "        my_dict[a_nm1_gram] = [next_word]                       # a_nm1_gram is a new key. So, initialize the dictionary entry.\n",
    "    else:\n",
    "        my_dict[a_nm1_gram] += [next_word]                      # an_nm1_gram is already in the dictionary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OUKRAz_Zfg6w",
    "outputId": "0b9ae7c4-683b-4219-bbc6-d1670da00415",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# View the dictionary.\n",
    "my_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRT2ezB_fg6w"
   },
   "source": [
    "#### 1.3. Predict the next word:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Qmvap8yYfg6x"
   },
   "outputs": [],
   "source": [
    "# Helper function that picks the following word.\n",
    "def predict_next(a_nm1_gram):\n",
    "    value_list_size = len(my_dict[a_nm1_gram])         # length of the value corresponding to the key = a_nm1_gram.\n",
    "    i_pick = randint(0, value_list_size)               # A random number from the range 0 ~ value_list_size.\n",
    "    return(my_dict[a_nm1_gram][i_pick])                  # Return the randomly chosen next word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JU09hw-tfg6x",
    "outputId": "2ca03488-f93f-44aa-b9ce-9d4d5a59881e"
   },
   "outputs": [],
   "source": [
    "# Test.\n",
    "input_str = 'order to'                                 # Has to be a VALID (n-1)-Gram!\n",
    "predict_next(input_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KZ3N4M-Pfg6x",
    "outputId": "9cdac9a4-fd5b-419a-a3cd-4655615b5e44"
   },
   "outputs": [],
   "source": [
    "# Another test.\n",
    "# Repeat for 10 times and see that the next word is chosen randomly with a probability proportional to the occurrence.\n",
    "input_str = 'machine learning'                                 # Has to be a VALID (n-1)-Gram!\n",
    "for i in range(10):\n",
    "    print(predict_next(input_str))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LFWV9C2Ofg6x"
   },
   "source": [
    "#### 1.4. Predict a sequence:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sIwLI5W7fg6y"
   },
   "outputs": [],
   "source": [
    "# Initialize the random seed.\n",
    "seed(123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NwimcCa9fg6y"
   },
   "outputs": [],
   "source": [
    "# A seed string has to be input by the user.\n",
    "my_seed_str = 'machine learning'                                   # Has to be a VALID (n-1)-Gram!\n",
    "# my_seed_str = 'in order'                                         # Has to be a VALID (n-1)-Gram!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jqN1cIqkfg6y"
   },
   "outputs": [],
   "source": [
    "a_nm1_gram = my_seed_str\n",
    "output_string = my_seed_str                                         # Initialize the output string.\n",
    "while a_nm1_gram in my_dict:\n",
    "    output_string += \" \" + predict_next(a_nm1_gram)\n",
    "    words = nltk.word_tokenize(output_string)\n",
    "    a_nm1_gram = ' '.join(words[-n+1:])                            # Update a_nm1_gram."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "dDUQJ-6Gfg6y",
    "outputId": "e4d5ffa5-ebab-4aef-f165-3da194c77267"
   },
   "outputs": [],
   "source": [
    "# Output the predicted sequence.\n",
    "output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jc8alRYnfg6z"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
